- step:
    name: inference
    image: pytorch/pytorch:1.9.0-cuda10.2-cudnn7-runtime
    command:
      - python -m eval_image_retrieval_sequential.py {parameters}
    inputs:
      - name: data/OxfordParis/datasets/roxford5k
        default:
          - http://www.robots.ox.ac.uk/~vgg/data/oxbuildings/oxbuild_images.tgz
      - name: data/OxfordParis/datasets/rparis6k
        default:
          - http://www.robots.ox.ac.uk/~vgg/data/parisbuildings/paris_1.tgz
          - http://www.robots.ox.ac.uk/~vgg/data/parisbuildings/paris_2.tgz
    parameters:
      - name: imsize
        description: Input image size
        type: integer
        default: 512
      - name: multiscale
        description: Whether to enable multiscale image feature extraction or not
        type: flag
        pass-true-as: --multiscale=1
        pass-false-as: --multiscale=0
        default: true
      - name: data_path
        description: /path/to/revisited_paris_oxford/
        type: string
        default: data/OxfordParis
      - name: dataset
        description: Name of the dataset to use
        type: string
        default: rparis6k
      - name: pretrained_weights
        description: Path to pretrained weights to evaluate
        type: string
        default:
        optional: true
      - name: arch
        description: Architecture
        type: string
        default: vit_small
        optional: true
      - name: patch_size
        description: Patch resolution of the model
        type: integer
        default: 16
        optional: true
      - name: checkpoint_key
        description: "Key to use in the checkpoint (exemple: 'teacher')"
        type: string
        default: teacher
        optional: true