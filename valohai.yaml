- step:
    name: data_preparation
    environment: jellysmack-aws-us-west-2-p2-xlarge
    image: pytorch/pytorch:1.9.0-cuda10.2-cudnn7-runtime
    command:
      - pip install pandas
      - tar -zxvf /valohai/inputs/data/food-101.tar.gz -C /valohai/inputs/data
      - python -m prepare_data {parameters}
    inputs:
      - name: data
        default:
          - s3://jsk-valohai/dino-image-retrieval/data/food-101.tar.gz
    parameters:
      - name: imsize
        description: Input image size
        type: integer
        default: 512
      - name: multiscale
        description: Whether to enable multiscale image feature extraction or not
        type: flag
        pass-true-as: --multiscale=1
        pass-false-as: --multiscale=0
        default: true
      - name: data_path
        description: /path/to/dataset/
        type: string
        default: /valohai/inputs/data/food-101
      - name: dataset_fraction
        description: Floating number between 0 and 1 representing the fraction of the dataset we will use (e.g., 0.1 means we use 10% of all images in the dataset)
        type: float
        default: 0.1
      - name: output_path
        description: /path/to/where/computed/features/will/be/saved
        type: string
        default: /valohai/outputs/
      - name: output_prefix
        description: Prefix prepended to output features and labels filenames
        type: string
        default: dino
      - name: distributed
        description: Whether to enable distributed computing or not
        type: flag
        pass-true-as: --distributed=1
        pass-false-as: --distributed=0
        default: true

- step:
    name: training
    environment: jellysmack-aws-us-west-2-c5-xlarge
    image: pytorch/pytorch:1.9.0-cuda10.2-cudnn7-runtime
    command:
      - pip install valohai-utils
      - python -m train {parameters}
    inputs:
      - name: features_and_labels
        default:
          - datum://017c85c0-20dd-740d-4b4b-2fda4db6ae60
          - datum://017c85c0-1a80-b328-be26-120e6950bcc2
          - datum://017c85c0-13b7-70b2-28c3-f41b95010b79
          - datum://017c85c0-09fa-d32c-540a-76e8976c6458
    parameters:
      - name: data_path
        description: /path/to/dataset/
        type: string
        default: /valohai/inputs/features_and_labels/
      - name: input_prefix
        description: Prefix prepended to input features and labels filenames
        type: string
        default: dino
      - name: metrics_outpath
        description: /destination/path/for/metrics_logging/
        type: string
        default: /valohai/outputs/
      - name: epochs
        description: Num of epochs
        type: integer
        default: 100
      - name: batch_size
        description: Batch size
        type: integer
        default: 512
      - name: n_hidden_layers
        description: Num of hiddent layers in MLP
        type: integer
        default: 1
      - name: learning_rate
        description: Learning rate
        type: float
        default: 0.035
      - name: momentum
        description: SGD optimizer momentum
        type: float
        default: 0.9
      - name: distributed
        description: Whether to enable distributed computing or not
        type: flag
        pass-true-as: --distributed=1
        pass-false-as: --distributed=0
        default: false

- step:
    name: compare
    environment: jellysmack-aws-us-west-2-c5-xlarge
    image: pytorch/pytorch:1.9.0-cuda10.2-cudnn7-runtime
    command:
      - pip install valohai-utils fire
      - python -m compare {parameters}
    inputs:
      - name: metrics
    parameters:
      - name: metrics_dir
        description: /path/to/metrics/files/to/compare/
        type: string
        default: /valohai/inputs/metrics/







