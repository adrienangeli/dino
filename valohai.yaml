- step:
    name: inference
    image: pytorch/pytorch:1.9.0-cuda10.2-cudnn7-runtime
    command:
      - tar -zxvf /valohai/inputs/data/OxfordParis.tgz
      - python -m eval_image_retrieval_sequential {parameters}
    inputs:
      - name: data
        default:
          - s3://jsk-valohai/dino-image-retrieval/data/OxfordParis.tgz

    parameters:
      - name: imsize
        description: Input image size
        type: integer
        default: 512
      - name: multiscale
        description: Whether to enable multiscale image feature extraction or not
        type: flag
        pass-true-as: --multiscale=1
        pass-false-as: --multiscale=0
        default: true
      - name: data_path
        description: /path/to/revisited_paris_oxford/
        type: string
        default: /valohai/inputs/data/OxfordParis/datasets
      - name: dataset
        description: Name of the dataset to use
        type: string
        default: rparis6k
      - name: pretrained_weights
        description: Path to pretrained weights to evaluate
        type: string
        default:
        optional: true
      - name: arch
        description: Architecture
        type: string
        default: vit_small
        optional: true
      - name: patch_size
        description: Patch resolution of the model
        type: integer
        default: 16
        optional: true
      - name: checkpoint_key
        description: "Key to use in the checkpoint (exemple: 'teacher')"
        type: string
        default: teacher
        optional: true